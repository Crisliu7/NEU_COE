{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks for Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State of art weight Initialization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "  \"\"\"Set the parameter initialization using the method described.\n",
    "  This method is designed to keep the scale of the gradients roughly the same\n",
    "  in all layers.\n",
    "  Xavier Glorot and Yoshua Bengio (2010):\n",
    "           Understanding the difficulty of training deep feedforward neural\n",
    "           networks. International conference on artificial intelligence and\n",
    "           statistics.\n",
    "  Args:\n",
    "    n_inputs: The number of input nodes into each output.\n",
    "    n_outputs: The number of output nodes for each input.\n",
    "    uniform: If true use a uniform distribution, otherwise use a normal.\n",
    "  Returns:\n",
    "    An initializer.\n",
    "  \"\"\"\n",
    "  if uniform:\n",
    "    # 6 was used in the paper.\n",
    "    init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "    return tf.random_uniform_initializer(-init_range, init_range)\n",
    "  else:\n",
    "    # 3 gives us approximately the same limits as above since this repicks\n",
    "    # values greater than 2 standard deviations from the mean.\n",
    "    stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "    return tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''A recent paper by He, Rang, Zhen and Sun they build on Glorot & Bengio and suggest using 2/size_of_input_neuron\n",
    "''' \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "#     xavier_stddev = 1. / in_dim\n",
    "#     xavier_stddev = 2. / in_dim\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([784, 128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([100, 128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([128, 784]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter: 0\n",
      "D loss: 1.415\n",
      "G_loss: 2.379\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.009721\n",
      "G_loss: 7.341\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.02247\n",
      "G_loss: 5.915\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.0993\n",
      "G_loss: 6.051\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.07339\n",
      "G_loss: 5.495\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.2982\n",
      "G_loss: 4.846\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.4701\n",
      "G_loss: 4.655\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 0.4002\n",
      "G_loss: 4.265\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.5393\n",
      "G_loss: 4.193\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.5715\n",
      "G_loss: 3.293\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.3878\n",
      "G_loss: 3.643\n",
      "\n",
      "Iter: 11000\n",
      "D loss: 0.7258\n",
      "G_loss: 2.462\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.5642\n",
      "G_loss: 3.138\n",
      "\n",
      "Iter: 13000\n",
      "D loss: 0.849\n",
      "G_loss: 2.389\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.5824\n",
      "G_loss: 2.922\n",
      "\n",
      "Iter: 15000\n",
      "D loss: 0.6598\n",
      "G_loss: 3.007\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.7555\n",
      "G_loss: 2.602\n",
      "\n",
      "Iter: 17000\n",
      "D loss: 0.662\n",
      "G_loss: 2.606\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.786\n",
      "G_loss: 2.466\n",
      "\n",
      "Iter: 19000\n",
      "D loss: 0.7859\n",
      "G_loss: 2.022\n",
      "\n",
      "Iter: 20000\n",
      "D loss: 0.828\n",
      "G_loss: 2.317\n",
      "\n",
      "Iter: 21000\n",
      "D loss: 0.7157\n",
      "G_loss: 2.249\n",
      "\n",
      "Iter: 22000\n",
      "D loss: 0.6598\n",
      "G_loss: 2.131\n",
      "\n",
      "Iter: 23000\n",
      "D loss: 0.8062\n",
      "G_loss: 2.752\n",
      "\n",
      "Iter: 24000\n",
      "D loss: 0.7998\n",
      "G_loss: 2.511\n",
      "\n",
      "Iter: 25000\n",
      "D loss: 0.7286\n",
      "G_loss: 2.13\n",
      "\n",
      "Iter: 26000\n",
      "D loss: 0.7427\n",
      "G_loss: 2.468\n",
      "\n",
      "Iter: 27000\n",
      "D loss: 0.7229\n",
      "G_loss: 2.55\n",
      "\n",
      "Iter: 28000\n",
      "D loss: 0.7388\n",
      "G_loss: 2.125\n",
      "\n",
      "Iter: 29000\n",
      "D loss: 0.7664\n",
      "G_loss: 2.435\n",
      "\n",
      "Iter: 30000\n",
      "D loss: 0.62\n",
      "G_loss: 2.332\n",
      "\n",
      "Iter: 31000\n",
      "D loss: 0.6681\n",
      "G_loss: 2.594\n",
      "\n",
      "Iter: 32000\n",
      "D loss: 0.785\n",
      "G_loss: 2.152\n",
      "\n",
      "Iter: 33000\n",
      "D loss: 0.733\n",
      "G_loss: 1.873\n",
      "\n",
      "Iter: 34000\n",
      "D loss: 0.8573\n",
      "G_loss: 2.092\n",
      "\n",
      "Iter: 35000\n",
      "D loss: 0.6817\n",
      "G_loss: 1.87\n",
      "\n",
      "Iter: 36000\n",
      "D loss: 0.6317\n",
      "G_loss: 2.435\n",
      "\n",
      "Iter: 37000\n",
      "D loss: 0.58\n",
      "G_loss: 2.573\n",
      "\n",
      "Iter: 38000\n",
      "D loss: 0.6915\n",
      "G_loss: 2.579\n",
      "\n",
      "Iter: 39000\n",
      "D loss: 0.6295\n",
      "G_loss: 1.87\n",
      "\n",
      "Iter: 40000\n",
      "D loss: 0.5399\n",
      "G_loss: 2.328\n",
      "\n",
      "Iter: 41000\n",
      "D loss: 0.5294\n",
      "G_loss: 2.986\n",
      "\n",
      "Iter: 42000\n",
      "D loss: 0.6353\n",
      "G_loss: 2.391\n",
      "\n",
      "Iter: 43000\n",
      "D loss: 0.6774\n",
      "G_loss: 2.42\n",
      "\n",
      "Iter: 44000\n",
      "D loss: 0.6536\n",
      "G_loss: 2.098\n",
      "\n",
      "Iter: 45000\n",
      "D loss: 0.6789\n",
      "G_loss: 2.737\n",
      "\n",
      "Iter: 46000\n",
      "D loss: 0.5624\n",
      "G_loss: 2.48\n",
      "\n",
      "Iter: 47000\n",
      "D loss: 0.5994\n",
      "G_loss: 2.616\n",
      "\n",
      "Iter: 48000\n",
      "D loss: 0.6223\n",
      "G_loss: 2.355\n",
      "\n",
      "Iter: 49000\n",
      "D loss: 0.4919\n",
      "G_loss: 2.395\n",
      "\n",
      "Iter: 50000\n",
      "D loss: 0.6991\n",
      "G_loss: 2.534\n",
      "\n",
      "Iter: 51000\n",
      "D loss: 0.5222\n",
      "G_loss: 2.153\n",
      "\n",
      "Iter: 52000\n",
      "D loss: 0.6752\n",
      "G_loss: 2.252\n",
      "\n",
      "Iter: 53000\n",
      "D loss: 0.523\n",
      "G_loss: 2.72\n",
      "\n",
      "Iter: 54000\n",
      "D loss: 0.6443\n",
      "G_loss: 2.746\n",
      "\n",
      "Iter: 55000\n",
      "D loss: 0.5706\n",
      "G_loss: 2.398\n",
      "\n",
      "Iter: 56000\n",
      "D loss: 0.619\n",
      "G_loss: 2.474\n",
      "\n",
      "Iter: 57000\n",
      "D loss: 0.711\n",
      "G_loss: 2.446\n",
      "\n",
      "Iter: 58000\n",
      "D loss: 0.5488\n",
      "G_loss: 2.593\n",
      "\n",
      "Iter: 59000\n",
      "D loss: 0.5521\n",
      "G_loss: 2.562\n",
      "\n",
      "Iter: 60000\n",
      "D loss: 0.6504\n",
      "G_loss: 2.872\n",
      "\n",
      "Iter: 61000\n",
      "D loss: 0.6151\n",
      "G_loss: 2.388\n",
      "\n",
      "Iter: 62000\n",
      "D loss: 0.745\n",
      "G_loss: 2.503\n",
      "\n",
      "Iter: 63000\n",
      "D loss: 0.5456\n",
      "G_loss: 2.15\n",
      "\n",
      "Iter: 64000\n",
      "D loss: 0.6548\n",
      "G_loss: 1.873\n",
      "\n",
      "Iter: 65000\n",
      "D loss: 0.6432\n",
      "G_loss: 2.498\n",
      "\n",
      "Iter: 66000\n",
      "D loss: 0.6463\n",
      "G_loss: 2.11\n",
      "\n",
      "Iter: 67000\n",
      "D loss: 0.7626\n",
      "G_loss: 2.384\n",
      "\n",
      "Iter: 68000\n",
      "D loss: 0.5286\n",
      "G_loss: 2.594\n",
      "\n",
      "Iter: 69000\n",
      "D loss: 0.6414\n",
      "G_loss: 2.634\n",
      "\n",
      "Iter: 70000\n",
      "D loss: 0.6778\n",
      "G_loss: 2.182\n",
      "\n",
      "Iter: 71000\n",
      "D loss: 0.5553\n",
      "G_loss: 2.184\n",
      "\n",
      "Iter: 72000\n",
      "D loss: 0.5617\n",
      "G_loss: 2.412\n",
      "\n",
      "Iter: 73000\n",
      "D loss: 0.5488\n",
      "G_loss: 2.725\n",
      "\n",
      "Iter: 74000\n",
      "D loss: 0.5284\n",
      "G_loss: 2.612\n",
      "\n",
      "Iter: 75000\n",
      "D loss: 0.573\n",
      "G_loss: 2.319\n",
      "\n",
      "Iter: 76000\n",
      "D loss: 0.6127\n",
      "G_loss: 2.677\n",
      "\n",
      "Iter: 77000\n",
      "D loss: 0.5276\n",
      "G_loss: 2.269\n",
      "\n",
      "Iter: 78000\n",
      "D loss: 0.5939\n",
      "G_loss: 2.581\n",
      "\n",
      "Iter: 79000\n",
      "D loss: 0.5148\n",
      "G_loss: 2.572\n",
      "\n",
      "Iter: 80000\n",
      "D loss: 0.5406\n",
      "G_loss: 2.687\n",
      "\n",
      "Iter: 81000\n",
      "D loss: 0.4844\n",
      "G_loss: 2.279\n",
      "\n",
      "Iter: 82000\n",
      "D loss: 0.6676\n",
      "G_loss: 2.433\n",
      "\n",
      "Iter: 83000\n",
      "D loss: 0.6074\n",
      "G_loss: 2.194\n",
      "\n",
      "Iter: 84000\n",
      "D loss: 0.6843\n",
      "G_loss: 2.194\n",
      "\n",
      "Iter: 85000\n",
      "D loss: 0.643\n",
      "G_loss: 2.516\n",
      "\n",
      "Iter: 86000\n",
      "D loss: 0.5326\n",
      "G_loss: 2.284\n",
      "\n",
      "Iter: 87000\n",
      "D loss: 0.5262\n",
      "G_loss: 2.506\n",
      "\n",
      "Iter: 88000\n",
      "D loss: 0.4589\n",
      "G_loss: 2.601\n",
      "\n",
      "Iter: 89000\n",
      "D loss: 0.5043\n",
      "G_loss: 2.323\n",
      "\n",
      "Iter: 90000\n",
      "D loss: 0.5627\n",
      "G_loss: 2.798\n",
      "\n",
      "Iter: 91000\n",
      "D loss: 0.5558\n",
      "G_loss: 2.51\n",
      "\n",
      "Iter: 92000\n",
      "D loss: 0.5002\n",
      "G_loss: 2.558\n",
      "\n",
      "Iter: 93000\n",
      "D loss: 0.5895\n",
      "G_loss: 2.633\n",
      "\n",
      "Iter: 94000\n",
      "D loss: 0.3963\n",
      "G_loss: 2.9\n",
      "\n",
      "Iter: 95000\n",
      "D loss: 0.5494\n",
      "G_loss: 2.214\n",
      "\n",
      "Iter: 96000\n",
      "D loss: 0.5786\n",
      "G_loss: 2.562\n",
      "\n",
      "Iter: 97000\n",
      "D loss: 0.475\n",
      "G_loss: 2.415\n",
      "\n",
      "Iter: 98000\n",
      "D loss: 0.6267\n",
      "G_loss: 2.706\n",
      "\n",
      "Iter: 99000\n",
      "D loss: 0.5698\n",
      "G_loss: 2.643\n",
      "\n",
      "Iter: 100000\n",
      "D loss: 0.4741\n",
      "G_loss: 2.264\n",
      "\n",
      "Iter: 101000\n",
      "D loss: 0.5731\n",
      "G_loss: 2.698\n",
      "\n",
      "Iter: 102000\n",
      "D loss: 0.4556\n",
      "G_loss: 2.576\n",
      "\n",
      "Iter: 103000\n",
      "D loss: 0.4566\n",
      "G_loss: 2.594\n",
      "\n",
      "Iter: 104000\n",
      "D loss: 0.5108\n",
      "G_loss: 2.718\n",
      "\n",
      "Iter: 105000\n",
      "D loss: 0.4266\n",
      "G_loss: 2.39\n",
      "\n",
      "Iter: 106000\n",
      "D loss: 0.4953\n",
      "G_loss: 2.58\n",
      "\n",
      "Iter: 107000\n",
      "D loss: 0.5537\n",
      "G_loss: 2.801\n",
      "\n",
      "Iter: 108000\n",
      "D loss: 0.6355\n",
      "G_loss: 2.618\n",
      "\n",
      "Iter: 109000\n",
      "D loss: 0.4918\n",
      "G_loss: 2.779\n",
      "\n",
      "Iter: 110000\n",
      "D loss: 0.5706\n",
      "G_loss: 2.516\n",
      "\n",
      "Iter: 111000\n",
      "D loss: 0.5657\n",
      "G_loss: 2.434\n",
      "\n",
      "Iter: 112000\n",
      "D loss: 0.4994\n",
      "G_loss: 2.508\n",
      "\n",
      "Iter: 113000\n",
      "D loss: 0.5182\n",
      "G_loss: 3.007\n",
      "\n",
      "Iter: 114000\n",
      "D loss: 0.4292\n",
      "G_loss: 2.684\n",
      "\n",
      "Iter: 115000\n",
      "D loss: 0.483\n",
      "G_loss: 2.722\n",
      "\n",
      "Iter: 116000\n",
      "D loss: 0.5251\n",
      "G_loss: 2.336\n",
      "\n",
      "Iter: 117000\n",
      "D loss: 0.4974\n",
      "G_loss: 2.907\n",
      "\n",
      "Iter: 118000\n",
      "D loss: 0.4847\n",
      "G_loss: 2.57\n",
      "\n",
      "Iter: 119000\n",
      "D loss: 0.4795\n",
      "G_loss: 2.533\n",
      "\n",
      "Iter: 120000\n",
      "D loss: 0.6038\n",
      "G_loss: 2.894\n",
      "\n",
      "Iter: 121000\n",
      "D loss: 0.5402\n",
      "G_loss: 2.599\n",
      "\n",
      "Iter: 122000\n",
      "D loss: 0.4463\n",
      "G_loss: 2.959\n",
      "\n",
      "Iter: 123000\n",
      "D loss: 0.548\n",
      "G_loss: 2.719\n",
      "\n",
      "Iter: 124000\n",
      "D loss: 0.5302\n",
      "G_loss: 2.601\n",
      "\n",
      "Iter: 125000\n",
      "D loss: 0.3993\n",
      "G_loss: 2.712\n",
      "\n",
      "Iter: 126000\n",
      "D loss: 0.4029\n",
      "G_loss: 2.723\n",
      "\n",
      "Iter: 127000\n",
      "D loss: 0.3489\n",
      "G_loss: 2.87\n",
      "\n",
      "Iter: 128000\n",
      "D loss: 0.6726\n",
      "G_loss: 3.029\n",
      "\n",
      "Iter: 129000\n",
      "D loss: 0.5091\n",
      "G_loss: 2.64\n",
      "\n",
      "Iter: 130000\n",
      "D loss: 0.476\n",
      "G_loss: 2.761\n",
      "\n",
      "Iter: 131000\n",
      "D loss: 0.435\n",
      "G_loss: 3.235\n",
      "\n",
      "Iter: 132000\n",
      "D loss: 0.5114\n",
      "G_loss: 3.097\n",
      "\n",
      "Iter: 133000\n",
      "D loss: 0.4661\n",
      "G_loss: 3.117\n",
      "\n",
      "Iter: 134000\n",
      "D loss: 0.5536\n",
      "G_loss: 2.813\n",
      "\n",
      "Iter: 135000\n",
      "D loss: 0.6208\n",
      "G_loss: 2.924\n",
      "\n",
      "Iter: 136000\n",
      "D loss: 0.4981\n",
      "G_loss: 2.746\n",
      "\n",
      "Iter: 137000\n",
      "D loss: 0.5282\n",
      "G_loss: 3.128\n",
      "\n",
      "Iter: 138000\n",
      "D loss: 0.4717\n",
      "G_loss: 2.843\n",
      "\n",
      "Iter: 139000\n",
      "D loss: 0.4332\n",
      "G_loss: 2.842\n",
      "\n",
      "Iter: 140000\n",
      "D loss: 0.5254\n",
      "G_loss: 2.631\n",
      "\n",
      "Iter: 141000\n",
      "D loss: 0.5741\n",
      "G_loss: 3.254\n",
      "\n",
      "Iter: 142000\n",
      "D loss: 0.4683\n",
      "G_loss: 3.504\n",
      "\n",
      "Iter: 143000\n",
      "D loss: 0.6296\n",
      "G_loss: 3.018\n",
      "\n",
      "Iter: 144000\n",
      "D loss: 0.4316\n",
      "G_loss: 2.649\n",
      "\n",
      "Iter: 145000\n",
      "D loss: 0.4326\n",
      "G_loss: 3.063\n",
      "\n",
      "Iter: 146000\n",
      "D loss: 0.4091\n",
      "G_loss: 2.685\n",
      "\n",
      "Iter: 147000\n",
      "D loss: 0.5257\n",
      "G_loss: 2.573\n",
      "\n",
      "Iter: 148000\n",
      "D loss: 0.4989\n",
      "G_loss: 2.839\n",
      "\n",
      "Iter: 149000\n",
      "D loss: 0.4743\n",
      "G_loss: 2.885\n",
      "\n",
      "Iter: 150000\n",
      "D loss: 0.3932\n",
      "G_loss: 2.7\n",
      "\n",
      "Iter: 151000\n",
      "D loss: 0.3878\n",
      "G_loss: 3.096\n",
      "\n",
      "Iter: 152000\n",
      "D loss: 0.4717\n",
      "G_loss: 2.918\n",
      "\n",
      "Iter: 153000\n",
      "D loss: 0.3773\n",
      "G_loss: 2.846\n",
      "\n",
      "Iter: 154000\n",
      "D loss: 0.3639\n",
      "G_loss: 2.797\n",
      "\n",
      "Iter: 155000\n",
      "D loss: 0.3633\n",
      "G_loss: 3.036\n",
      "\n",
      "Iter: 156000\n",
      "D loss: 0.4571\n",
      "G_loss: 3.234\n",
      "\n",
      "Iter: 157000\n",
      "D loss: 0.4808\n",
      "G_loss: 3.019\n",
      "\n",
      "Iter: 158000\n",
      "D loss: 0.4611\n",
      "G_loss: 2.875\n",
      "\n",
      "Iter: 159000\n",
      "D loss: 0.4031\n",
      "G_loss: 2.85\n",
      "\n",
      "Iter: 160000\n",
      "D loss: 0.3588\n",
      "G_loss: 3.129\n",
      "\n",
      "Iter: 161000\n",
      "D loss: 0.4162\n",
      "G_loss: 3.408\n",
      "\n",
      "Iter: 162000\n",
      "D loss: 0.5417\n",
      "G_loss: 3.113\n",
      "\n",
      "Iter: 163000\n",
      "D loss: 0.498\n",
      "G_loss: 2.963\n",
      "\n",
      "Iter: 164000\n",
      "D loss: 0.4169\n",
      "G_loss: 2.896\n",
      "\n",
      "Iter: 165000\n",
      "D loss: 0.4234\n",
      "G_loss: 3.384\n",
      "\n",
      "Iter: 166000\n",
      "D loss: 0.4215\n",
      "G_loss: 3.43\n",
      "\n",
      "Iter: 167000\n",
      "D loss: 0.3511\n",
      "G_loss: 3.035\n",
      "\n",
      "Iter: 168000\n",
      "D loss: 0.4011\n",
      "G_loss: 3.949\n",
      "\n",
      "Iter: 169000\n",
      "D loss: 0.4141\n",
      "G_loss: 2.983\n",
      "\n",
      "Iter: 170000\n",
      "D loss: 0.477\n",
      "G_loss: 2.665\n",
      "\n",
      "Iter: 171000\n",
      "D loss: 0.5037\n",
      "G_loss: 3.167\n",
      "\n",
      "Iter: 172000\n",
      "D loss: 0.4957\n",
      "G_loss: 3.13\n",
      "\n",
      "Iter: 173000\n",
      "D loss: 0.2821\n",
      "G_loss: 3.088\n",
      "\n",
      "Iter: 174000\n",
      "D loss: 0.3529\n",
      "G_loss: 2.883\n",
      "\n",
      "Iter: 175000\n",
      "D loss: 0.3142\n",
      "G_loss: 3.615\n",
      "\n",
      "Iter: 176000\n",
      "D loss: 0.4902\n",
      "G_loss: 2.78\n",
      "\n",
      "Iter: 177000\n",
      "D loss: 0.4901\n",
      "G_loss: 3.225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 128\n",
    "Z_dim = 100\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(1000000):\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_mb, _ = mnist.train.next_batch(minibatch_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(minibatch_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(minibatch_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After checking images in `out` dir we see that the GAN [mode collapsed](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/)\n",
    "Fix for that is to let discriminator see ground truth in mini batches\n",
    "\n",
    "** Here's a YouTube of I made from all 1000 images at 100ms delay **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ktxhiKhWoEE?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
